---
title: "Exploratory Data Analysis with R's Ggplot2"
author: "Sarah Hosking"
date: "October 19, 2017"
output: 
  slidy_presentation:
    font_adjustment: +2
    fig_width: 7
    fig_height: 5

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      include = TRUE,
                      message = FALSE,
                      warning = FALSE)
#library(lubridate)
library(tidyverse)
theme_set(theme_bw())

```

# Why visual EDA?

Example: Anscombe's quartet

```{r anscombe}

anscombe

```

# Stats vs Plots

Same mean and standard deviation...

```{r calc anscombe stats, include=FALSE}

# calc mean and standard dev
mean = round(apply(anscombe,2, mean),3)
std_dev = round(apply(anscombe,2, sd), 3)

# create df of stats
anscombe_stats <- rbind(mean, std_dev) 

```

```{r show stats}

anscombe_stats

```

...but plots tell a better story

```{r convert to long df}

# create long df of anscombe data
mydata=with(anscombe,data.frame(xVal=c(x1,x2,x3,x4), 
                                yVal=c(y1,y2,y3,y4),
                                mygroup=gl(4,nrow(anscombe))))

```


```{r plot mydata}

ggplot(data = mydata, aes(x = xVal, y = yVal, shape = mygroup)) +
  geom_point(size = 3) +
  facet_wrap(~mygroup)


```


# Why R?

* open-source
* mature ecosystem
* made for stats
* easy to share work
* fantastic IDE, _RStudio_

# Why Ggplot2?

![](layer_cake.jpg)

# Ggplot layers in action

```{r build up layers}

# create plot data layer
p <- ggplot(data = mydata, aes(x = xVal, y = yVal)) 
p

# create geom layer
g = geom_point(size = 3)
p + g


# update plot
# map colour to group variable
p <- p %+% aes(shape = mygroup)
p + g

# facet by group
p + g + facet_wrap(~mygroup)

```

# Basic format

```{r, eval=FALSE, include=TRUE}

# formal
ggplot(data = df, aes(x = x_var, y = y_var)) +  # data layer
  geom_xxx()                                  # plot type

# using shortcuts
ggplot(df, aes(x_var, y_var)) +
  geom_xxx() 

# best practice
p <- ggplot(df, aes(x_var, y_var))

p + geom_xxx()
```

# Paris air quality data

![](ParisPollution.jpg)

```{r air pollution in paris Oct 2017}

airparif <- read_rds("airparif_oct2017.rds")
```

## What are we looking at?

Airparif =  Paris air quality monitoring network

```{r get names}

# get column names
names(airparif)

```

What the abbreviations mean:

* `PM25` = fine particulate < 2.5 mm
* `PM10` = fine particulate < 10 mm
* `03` = Ozone
* `NO2` = Nitrogen Dioxide (Azote)
* `CO` = Carbon monoxide

# Start exploring

```{r summary & structure}
dim(airparif)
str(airparif) # structure
summary(airparif) # min, max, quartiles + count of NAs
```

# Plot distributions

Particulate matter < 10mm

```{r distribution of PM10}

hg <- ggplot(airparif, aes(PM10)) + 
  geom_histogram()

hg

```

# Plot another distribution

Particulate matter < 2.5mm

```{r verbose way}

hg <- ggplot(airparif, aes(PM25)) +
  geom_histogram()
hg
```


# Seriously?

![](tedious.gif)


# Iterate faster

## Tip 1: Update instead

Update _data layer_ with `%+%`

```{r substitute}

hg %+% aes(PM25) + # replace x var with PM25
  geom_histogram()

```

## Tip 2: Use tidy data

Tidy means storing:

* observations in rows
* variables are columns
* values in cells

Not tidy

```{r not tidy}

head(airparif)
```


```{r tidyr + dplyr, include=FALSE}

airparif.tidy <- airparif %>% 
  gather(PM10, PM25, NO2, O3, CO, 
         key = 'pollutant', value = 'value', 
         na.rm = TRUE) %>% 
  group_by(date, heure, pollutant)

```

Tidy
 
```{r}

head(airparif.tidy)

```

# Tidy data = more grouping options

Update plot with new df and x variable.

```{r update plot with new df & x var}

# update df & x var
hg <- hg %+% airparif.tidy + aes(x = value)

# plot
hg + facet_wrap(~pollutant)

# fix x-axis
hg + facet_wrap(~pollutant, scales = 'free_x')
```

Add more visual elements

```{r update aes}

# update data layer with new mapping
hg <- hg %+% aes(fill = pollutant)

# show plot
hg + facet_wrap(~pollutant)
```


# Facet by 2 variables

Do distributions change from month to month?

```{r facet grid}

hg + facet_grid(month~pollutant, scales = 'free_x')

```


# Get a better look at outliers

Use boxplots

```{r boxplot}

# create boxplot var
bp <- ggplot(airparif.tidy, aes(month, value, fill = pollutant)) +
  geom_boxplot()

# we'll use this a lot  
fw <- facet_wrap(~pollutant, scales = 'free_y')

bp + fw

```

# Add more data

Add lines for the pollution thresholds

![](citeair-grille-calcul.png)

## Create df of thresholds

```{r show hourly pollution levels, include=FALSE}

# first, define thresholds for diff pollutants
PM10 <- c(25,50,90,180)
PM25 <- c(15,30,55,110)
NO2 <- c(50,100,200,400)
O3 <- c(60,120,180,240)
CO <- c(5000,7500, 10000, 20000)

# create df of levels
levels_h.df <- as.data.frame(cbind(PM10, PM25, NO2, O3, CO))
rownames(levels_h.df) <- c('low', 'medium', 'high', 'very high')

# set rownames as columns
library(data.table)
setDT(levels_h.df, keep.rownames = TRUE)

# rename rn column
colnames(levels_h.df)[1] <- "level"

# put in long format
levels_h.long <- levels_h.df %>% 
  gather('pollutant', 'value', 2:6)

# change col order
levels_h.long <- levels_h.long[, c(2,3,1)]

head(levels_h.long, 12)
```

## Add second geom & new df

Put things in perspective

```{r bp with pollution levels}

# add horizontal line
bp + fw +
  geom_hline(data = levels_h.long, 
                  aes(yintercept = value, group = pollutant), linetype = 2)

# make this a var, for easy reuse
hl <- geom_hline(data = levels_h.long, 
                  aes(yintercept = value, group = pollutant), linetype = 2)
```

What if we looked at hours instead?

```{r hourly dist}

# replace `month` with `heure'
bp <- bp %+% aes(x = as.factor(heure)) 

# facet & show levels
bp + fw + hl

# zoom in
bp + fw + cc


```

# Grouping

Show hourly changes throughout the day

```{r filter on dec 2016}

dec16 <- airparif.tidy %>% 
  filter(year == 2016 & month == 12)

```

```{r line plot}

p <- ggplot(dec16, aes(heure, value)) +
              geom_line(colour = 'darkgrey')
p + fw
```

# Change default grouping

```{r}

p <- p %+% aes(group = date)
p + fw
```



# When was the extreme day?

```{r filter data}

# Dec 2016 particulate data
dec16_pm <- dec16 %>% 
  filter(pollutant %in% c('PM10', 'PM25'))

# find index of max value in Dec
max_val <- which(dec16_pm$value == max(dec16_pm$value))

# find date
max_date <- dec16_pm[max_val, 'date']

# filter on this date
dec16_pm_max <- dec16 %>%
  filter(date == max_date$date)

```

```{r plot max PM10 day}

# data layer
p_max <- ggplot(dec16_pm_max, aes(heure, value, 
                                  group = pollutant, 
                                  colour = pollutant))
#plot
p_max + 
  geom_line() +
  fw
  

```

# Combine data sets

```{r}

p +                               # line plot of all days in Dec 2016
  geom_line(data = dec16_pm_max,  # line plot of spike day
            aes(heure, value, colour = pollutant)) + 
            hl +                  # pollution levels
            fw


```

# Create grid of variables

```{r}

# create a sample of 1000 obs

set.seed(888) 
sample <- subset(airparif, select = c(PM10, PM25, NO2, O3, CO, year))
sample <- sample[sample(1:nrow(sample),1000),]

```

```{r ggpairs}

# import library
library(GGally) 

# look at correlations
ggpairs(data=sample, # data.frame with variables
        title="Pollutant correlations") # title of the plot

```

```{r add alpha and trendline}

ggpairs(data = sample, 
        lower = list(continuous = wrap("smooth", alpha=1/5, shape = I('.'))), #add trendline, reduce opacity
         title="Pollutant correlations")

```

```{r ggpairs density}

ggpairs(data = sample, 
        lower = list(continuous = wrap("density", alpha = 1/2)), # display continuous vars as density plots
         title="Pollutant correlations")

```

# Do we still have time?

## Heatmap

```{r heatmap munging, eval=FALSE, include=FALSE}

# make wide df
ap.agg <- ap.tidy.agg %>%
  spread(pollutant, mean)

# scale by centering around mean
# for that pollutant
ap.scaled <- sapply(ap.agg[2:6], function(x) scale(x))

# convert to df
ap.scaled <- as.data.frame(ap.scaled)

# add back date
ap.scaled$date <- ap.agg$date

# make tidy
ap.scaled.tidy <- ap.scaled %>% 
  group_by(date) %>% 
  gather(key = 'pollutant', value = 'scale_value', 1:5) %>% 
  arrange(date)

head(ap.scaled.tidy)

```

```{r plot heatmap}

# plot heatmap
hm <- ggplot(data = ap.scaled.tidy, 
             aes(x = pollutant, y = as.factor(month(date))))

hm +
  geom_tile(aes(fill = scale_value)) +
  scale_fill_gradient2(low="blue", high="darkorange", guide="colorbar") +
  labs(title = 'Standardized daily pollution values', 
       subtitle = 'by pollutant and month')


```

```{r data munge hourly data, include=FALSE}

# data munging

# scale by centering around mean
# for that pollutant
ap.h.scaled <- sapply(airparif[3:7], function(x) scale(x))

# convert to df
ap.h.scaled <- as.data.frame(ap.h.scaled)

# add back date & hour
ap.h.scaled$date <- airparif$date
ap.h.scaled$hour <- airparif$heure

# make tidy
ap.h.scaled.tidy <- ap.h.scaled %>% 
  group_by(date, hour)%>% 
  gather(key = 'pollutant', value = 'scale_value', 1:5) %>% 
  arrange(date)

head(ap.h.scaled.tidy)

```

```{r hourly heatmap}
# plot
hm %+% ap.h.scaled.tidy + aes(x=pollutant, y=hour) +
  geom_tile(aes(fill = scale_value)) +
  scale_fill_gradient2(low="blue", 
                       high="darkorange", 
                       guide="colorbar") +
  labs(title = 'Standardized hourly pollution values')

```

## Zoom in

Beware of reducing axis range with distributions.

```{r coord_cartesian}

# no
bp + fw + scale_y_continuous(limits = c(0,75))

# yes
bp + fw + coord_cartesian(ylim = c(0,75))

# save as var for reuse
cc <- coord_cartesian(ylim = c(0,75))

```

# Learn more

data wrangling with R (dplyr & tidyr): https://s3.amazonaws.com/udacity-hosted-downloads/ud651/DataWranglingWithR.pdf

data.table package

ggplot cheatsheet: http://www.rstudio.com/wp-content/uploads/2015/03/ggplot2-cheatsheet.pdf

ggally tutorial: http://koaning.io/ggally-explore-all-the-things.html


